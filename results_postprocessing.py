"""
Post process the results from the summary.csv file generated by run_all_strategies_batch.py

Reads ./summary.csv, drops entire runs (run,seed) if any row in that run has N/A
scores or missing/zero baselines, normalizes area & buildings by the per-run
baseline, computes a composite = mean(norm_area, norm_bldg), and generates:

• plots/mean_normalized_area.png                (±SE; lower is better)
• plots/mean_normalized_buildings.png           (±SE; lower is better)
• plots/mean_composite.png                      (±SE; lower is better)
• plots/composite_per_run_scatter.png           (per-run consistency)
• plots/summary_stats.csv                       (per-strategy stats)
• plots/per_run_normalized_metrics.csv          (tidy per-run table)
• plots/mcts_win_stats.txt                      (how often MCTS wins)
"""

from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# -------- Settings (no CLI) --------
CSV_PATH = Path("summary_final_esper_high.csv")
OUTDIR = Path("plots_final_esper_high")

#these are the weights assigned to the area and building rewards used within the MCTS
COMPOSITE_WEIGHTS = (1/3, 2/3)  # (weight_area, weight_bldg), must sum to 1.0

# Exclusions, select runs to exclude (excludes entire runs, regardless of seed)
EXCLUDE_RUNS: set[int] = {9}   # esper high
# EXCLUDE_RUNS: set[int] = {43,49,91,     92,93,94,95,96,97}   # marshall med only up to 91 bd
# EXCLUDE_RUNS: set[int] = {0,105,110,12,36,53,94,9,46, 91,92,93,95}   # marshall high  only up to 46 bd
# Optional: exclude specific (run,seed) pairs if you ever need to

# EXCLUDE_RUNS: set[int] = {}   # esper high

EXCLUDE_RUN_UIDS: set[str] = set()  # e.g., {"15|42", "16|777"}


CATEGORY_COLORS = {
    "MCTS": "#4C72B0",                  # blue
    "Baseline": "#DD8452",              # orange
    "Rate-of-Spread–Driven": "#55A868", # green
    "Structure–Driven": "#8172B2",      # purple
    "Wind–Driven": "#C44E52",           # red
}
# --- Strategy name mapping (CSV → Publication name) ---
STRATEGY_NAME_MAP = {
    # MCTS
    "mcts": "MCTS",

    # Baseline
    "random": "Random Allocation",

    # Rate-of-Spread–Driven
    "ics_ros_weighted": "ROS–Truth",
    "ics_ros_weighted_mean": "ROS–Mean",

    # Structure–Driven
    "ics_buildings": "Structures–Exposure",
    "ics_mean_burned_buildings": "Structures–Outcome (Mean)",
    "ics_truth_burned_buildings": "Structures–Outcome (Truth)",

    # Wind–Driven
    "ics_dynamic": "Wind–Truth",
    "ics_dynamic_mean": "Wind–Mean",
    "ics_dynamic_mean_lookahead": "Wind–Mean Lookahead",
    "ics_dynamic_truth_lookahead": "Wind–Truth Lookahead",
}


# Map each strategy to its parent category
STRATEGY_CATEGORY = {
    # MCTS
    "MCTS": "MCTS",

    # Baseline
    "Random Allocation": "Baseline",

    # Rate-of-Spread–Driven
    "ROS–Truth": "Rate-of-Spread–Driven",
    "ROS–Mean": "Rate-of-Spread–Driven",

    # Structure–Driven
    "Structures–Exposure": "Structure–Driven",
    "Structures–Outcome (Mean)": "Structure–Driven",
    "Structures–Outcome (Truth)": "Structure–Driven",

    # Wind–Driven
    "Wind–Truth": "Wind–Driven",
    "Wind–Mean": "Wind–Driven",
    "Wind–Mean Lookahead": "Wind–Driven",
    "Wind–Truth Lookahead": "Wind–Driven",
}





def load_and_clean(csv_path: Path,
                   exclude_runs: set[int] | None = None,
                   exclude_run_uids: set[str] | None = None) -> pd.DataFrame:
    if not csv_path.exists():
        raise FileNotFoundError(f"Cannot find {csv_path.resolve()}")

    df = pd.read_csv(csv_path)

    # Ensure numeric, coerce "N/A" etc. to NaN
    for c in ["area_score", "buildings_destroyed", "baseline_area", "baseline_buildings"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # Robust run id = (run, seed)
    df["run_uid"] = df["run"].astype(str) + "|" + df["seed"].astype(str)

    n0 = len(df)
    if exclude_runs:
        df = df[~df["run"].isin(exclude_runs)].copy()
    if exclude_run_uids:
        df = df[~df["run_uid"].isin(exclude_run_uids)].copy()
    n_after_ex = len(df)




    # Drop an entire run if it has any NaN scores/baselines or zero baselines
    def run_is_bad(g: pd.DataFrame) -> bool:
        has_nan_scores = g["area_score"].isna().any() or g["buildings_destroyed"].isna().any()
        has_nan_baselines = g["baseline_area"].isna().any() or g["baseline_buildings"].isna().any()
        has_zero_baselines = (g["baseline_area"] == 0).any() or (g["baseline_buildings"] == 0).any()
        return bool(has_nan_scores or has_nan_baselines or has_zero_baselines)

    bad_runs = df.groupby("run_uid").apply(run_is_bad)
    bad_uids = set(bad_runs[bad_runs].index)
    if bad_uids:
        df = df[~df["run_uid"].isin(bad_uids)].copy()

    # Require MCTS present in a run for head-to-head
    df["strategy_lc"] = df["strategy"].astype(str).str.lower()
    uids_with_mcts = set(df.loc[df["strategy_lc"] == "mcts", "run_uid"].unique())
    df = df[df["run_uid"].isin(uids_with_mcts)].copy()
    # Replace strategy labels with publication-friendly names
    df["strategy"] = df["strategy"].map(STRATEGY_NAME_MAP).fillna(df["strategy"])

    if df.empty:
        raise RuntimeError("No usable rows after cleaning; check summary.csv.")

    # Normalized metrics (lower is better; 1.0 == baseline)
    df["norm_area"] = df["area_score"] / df["baseline_area"]
    df["norm_bldg"] = df["buildings_destroyed"] / df["baseline_buildings"]

    w_area, w_bldg = COMPOSITE_WEIGHTS
    df["composite"] = w_area * df["norm_area"] + w_bldg * df["norm_bldg"]

    return df


def summarize(df: pd.DataFrame) -> pd.DataFrame:
    summary = (
        df.groupby("strategy", as_index=False)
          .agg(
              n_runs=("run_uid", "nunique"),
              mean_norm_area=("norm_area", "mean"),
              std_norm_area=("norm_area", "std"),
              mean_norm_bldg=("norm_bldg", "mean"),
              std_norm_bldg=("norm_bldg", "std"),
              mean_composite=("composite", "mean"),
              std_composite=("composite", "std"),
          )
          .sort_values("mean_composite", ascending=True)
    )
    return summary


def compute_win_stats(df: pd.DataFrame) -> dict:
    pivot = df.pivot_table(index="run_uid", columns="strategy", values="composite", aggfunc="mean")

    strategies = list(pivot.columns)
    name_map = {s.lower(): s for s in strategies}
    if "mcts" not in name_map:
        raise RuntimeError("No 'mcts' strategy found after cleaning.")
    mcts_col = name_map["mcts"]

    # Strict best (lowest composite); counts ties separately
    best_mask = pivot.eq(pivot.min(axis=1), axis=0)
    mcts_best_runs = int(best_mask[mcts_col].sum())
    total_runs = int(best_mask[mcts_col].shape[0])

    h2h = {}
    for s in strategies:
        if s == mcts_col:
            continue
        both = pivot[[mcts_col, s]].dropna()
        wins = int((both[mcts_col] < both[s]).sum())
        ties = int((both[mcts_col] == both[s]).sum())
        losses = int((both[mcts_col] > both[s]).sum())
        h2h[s] = {"wins": wins, "ties": ties, "losses": losses, "samples": int(len(both))}

    return {
        "total_runs": total_runs,
        "mcts_best_runs": mcts_best_runs,
        "mcts_best_pct": (mcts_best_runs / total_runs * 100.0) if total_runs else np.nan,
        "head_to_head": h2h,
    }


def sem_or_std(x_like) -> float:
    x = pd.Series(x_like).dropna()
    if len(x) <= 1:
        return float(np.nan if len(x) == 0 else x.std(ddof=0))
    return float(x.std(ddof=1) / np.sqrt(len(x)))


# def bar_with_error(values, errors, labels, title, ylabel, outpath: Path):
#     fig = plt.figure(figsize=(10, 6))
#     x = np.arange(len(labels))
#     plt.bar(x, values, yerr=errors, capsize=6)
#     plt.axhline(1.0, linestyle="--", linewidth=1)  # baseline reference
#     plt.xticks(x, labels, rotation=20, ha="right")
#     plt.ylabel(ylabel)
#     plt.title(title)
#     plt.tight_layout()
#     fig.savefig(outpath, dpi=200)
#     plt.close(fig)

def bar_with_error(values, errors, labels, ylabel, outpath: Path):
    fig, ax = plt.subplots(figsize=(10, 6))
    x = np.arange(len(labels))

    # Determine colors by category
    colors = [
        CATEGORY_COLORS.get(STRATEGY_CATEGORY.get(lbl, "Baseline"), "#999999")
        for lbl in labels
    ]

    # Plot bars
    bars = ax.bar(
        x, values, yerr=errors, capsize=5,
        color=colors, edgecolor="black", linewidth=0.6
    )
    ax.axhline(1.0, linestyle="--", linewidth=1, color="gray", alpha=0.7)

    # Labels and formatting
    ax.set_xticks(x)
    ax.set_xticklabels(labels, rotation=25, ha="right")
    ax.set_ylabel(ylabel)
    ax.margins(y=0.1)
    ax.grid(axis="y", linestyle=":", alpha=0.6)

    # --- Legend ABOVE the chart ---
    from matplotlib.patches import Patch
    handles = [Patch(color=c, label=k) for k, c in CATEGORY_COLORS.items()]
    ax.legend(
        handles=handles,
        title="Category",
        loc="lower center",
        bbox_to_anchor=(0.5, 1.02),   # move above the plot area
        ncol=len(CATEGORY_COLORS),
        frameon=False,
    )

    fig.tight_layout()
    fig.savefig(outpath, dpi=200, bbox_inches="tight")
    plt.close(fig)




def scatter_composite(df: pd.DataFrame, outpath: Path):
    # Order strategies by mean composite
    order = (
        df.groupby("strategy")["composite"].mean()
          .sort_values(ascending=True)
          .index.tolist()
    )
    strat_to_x = {s: i for i, s in enumerate(order)}

    fig = plt.figure(figsize=(10, 6))
    xs = [strat_to_x[s] for s in df["strategy"]]
    ys = df["composite"].values

    # Jitter for visibility
    rng = np.random.default_rng(0)
    jitter = rng.normal(0, 0.06, size=len(xs))
    xs_jit = np.array(xs) + jitter

    plt.scatter(xs_jit, ys, alpha=0.6)
    plt.axhline(1.0, linestyle="--", linewidth=1)
    plt.xticks(range(len(order)), order, rotation=20, ha="right")
    plt.ylabel("Composite (mean of normalized area & buildings)")
    plt.title("Per-run composite by strategy (lower is better)")
    plt.tight_layout()
    fig.savefig(outpath, dpi=200)
    plt.close(fig)


def compute_best_counts(df: pd.DataFrame) -> pd.DataFrame:
    """
    For each metric (composite, norm_area, norm_bldg),
    count how many times each strategy achieves the best (lowest) value per run_uid.
    """
    metrics = ["composite", "norm_area", "norm_bldg"]
    results = []

    for metric in metrics:
        pivot = df.pivot_table(index="run_uid", columns="strategy", values=metric, aggfunc="mean")
        best_mask = pivot.eq(pivot.min(axis=1), axis=0)
        counts = best_mask.sum().rename(f"best_{metric}_count")
        results.append(counts)

    # Combine into one DataFrame
    out = pd.concat(results, axis=1).fillna(0).astype(int)
    out["total_best_count"] = out.sum(axis=1)
    out = out.reset_index().rename(columns={"strategy": "Strategy"})

    # Sort by total or composite count
    out = out.sort_values("best_composite_count", ascending=False)
    return out

def main():
    OUTDIR.mkdir(parents=True, exist_ok=True)

    df = load_and_clean(
        CSV_PATH,
        exclude_runs=EXCLUDE_RUNS,
        exclude_run_uids=EXCLUDE_RUN_UIDS
    )

    # Summary stats table (ordered by mean composite ascending)
    summary = summarize(df)
    summary_path = OUTDIR / "summary_stats.csv"
    summary.to_csv(summary_path, index=False)
    # --- ADD: summary + std + SE columns ---
    by_strat_for_stats = (
        df.groupby("strategy")
        .agg(
            std_norm_area=("norm_area", "std"),
            se_norm_area=("norm_area", sem_or_std),
            std_norm_bldg=("norm_bldg", "std"),
            se_norm_bldg=("norm_bldg", sem_or_std),
            std_composite=("composite", "std"),
            se_composite=("composite", sem_or_std),
        )
    )

    summary_with_stats = summary.merge(
        by_strat_for_stats, left_on="strategy", right_index=True, how="left"
    )
    summary_with_stats.to_csv(OUTDIR / "summary_stats_with_se.csv", index=False)
    # ---------------------------------------------------------------

    # Per-run mean composite values
    per_run = (
        df.groupby(["run_uid", "strategy"], as_index=False)["composite"].mean()
        .sort_values(["run_uid", "strategy"])
    )
    print("\n=== Mean composite per run (lower is better) ===")
    print(per_run.to_string(index=False))

    # Per-strategy means & standard errors (ordered by composite)
    by_strat = (
        df.groupby("strategy")
          .agg(mean_norm_area=("norm_area", "mean"),
               se_norm_area=("norm_area", sem_or_std),
               mean_norm_bldg=("norm_bldg", "mean"),
               se_norm_bldg=("norm_bldg", sem_or_std),
               mean_composite=("composite", "mean"),
               se_composite=("composite", sem_or_std))
          .loc[summary["strategy"]]  # align with composite order
    )
    labels = by_strat.index.tolist()

    # Plots
    bar_with_error(
        by_strat["mean_norm_area"].values,
        by_strat["se_norm_area"].values,
        labels,
        # title="Mean normalized AREA burned by strategy (±SE) — lower is better",
        ylabel="Normalized Area Burned",
        outpath=OUTDIR / "mean_normalized_area.png",
    )

    bar_with_error(
        by_strat["mean_norm_bldg"].values,
        by_strat["se_norm_bldg"].values,
        labels,
        # title="Mean normalized BUILDINGS destroyed by strategy (±SE) — lower is better",
        ylabel="Normalized Structures Destroyed",
        outpath=OUTDIR / "mean_normalized_buildings.png",
    )

    bar_with_error(
        by_strat["mean_composite"].values,
        by_strat["se_composite"].values,
        labels,
        # title="Mean COMPOSITE reward (±SE) — lower is better",
        ylabel="Composite Reward",
        outpath=OUTDIR / "mean_composite.png",
    )

    scatter_composite(df, OUTDIR / "composite_per_run_scatter.png")

    # Tidy per-run export
    tidy = (
        df[["run", "seed", "run_uid", "strategy", "norm_area", "norm_bldg", "composite"]]
        .sort_values(["run_uid", "strategy"])
    )
    tidy.to_csv(OUTDIR / "per_run_normalized_metrics.csv", index=False)

    # Win stats
    wins = compute_win_stats(df)
    # --- Compute "best score" counts ---
    best_counts = compute_best_counts(df)
    best_counts_path = OUTDIR / "best_score_counts.csv"
    best_counts.to_csv(best_counts_path, index=False)

    print("\n=== Count of times each strategy achieved best scores (lower = better) ===")
    print(best_counts.to_string(index=False))

    with open(OUTDIR / "mcts_win_stats.txt", "w", encoding="utf-8") as f:
        f.write(
            f"MCTS best in {wins['mcts_best_runs']}/{wins['total_runs']} runs "
            f"({wins['mcts_best_pct']:.1f}%).\n\nHead-to-head vs each strategy:\n"
        )
        for s, d in wins["head_to_head"].items():
            f.write(f"- {s}: {d['wins']} wins, {d['ties']} ties, {d['losses']} losses (n={d['samples']})\n")

    # --------------------------- ADD: LLM-ready tables ----------------------------
    # 1) Wide table (includes n_runs, mean, std, se for each metric)
    wide = (
        df.groupby("strategy")
        .agg(
            mean_norm_area=("norm_area", "mean"),
            std_norm_area=("norm_area", "std"),
            se_norm_area=("norm_area", sem_or_std),
            mean_norm_bldg=("norm_bldg", "mean"),
            std_norm_bldg=("norm_bldg", "std"),
            se_norm_bldg=("norm_bldg", sem_or_std),
            mean_composite=("composite", "mean"),
            std_composite=("composite", "std"),
            se_composite=("composite", sem_or_std),
        )
        .loc[summary["strategy"]]
        .reset_index()
    )
    wide.insert(1, "n_runs", summary.set_index("strategy").loc[wide["strategy"], "n_runs"].values)
    wide.to_csv(OUTDIR / "final_wide_with_se.csv", index=False)

    # 2) Long/tidy table (includes mean, std, se)
    parts = []
    metric_map = [
        ("Area", "mean_norm_area", "std_norm_area", "se_norm_area"),
        ("Buildings", "mean_norm_bldg", "std_norm_bldg", "se_norm_bldg"),
        ("Composite", "mean_composite", "std_composite", "se_composite"),
    ]
    for metric_name, mean_col, std_col, se_col in metric_map:
        tmp = wide[["strategy", "n_runs", mean_col, std_col, se_col]].copy()
        tmp = tmp.rename(columns={mean_col: "mean", std_col: "std", se_col: "se"})
        tmp["metric"] = metric_name
        parts.append(tmp)

    final_long = pd.concat(parts, axis=0, ignore_index=True)
    final_long = final_long[["strategy", "metric", "n_runs", "mean", "std", "se"]]
    final_long.to_csv(OUTDIR / "final_long_with_se.csv", index=False)
    # -----------------------------------------------------------------------------

    # Console quick look
    with pd.option_context("display.max_columns", 20, "display.width", 140):
        print("\n=== Summary (lower is better; sorted by mean composite) ===")
        print(summary.to_string(index=False))
    print(f"\nWrote outputs to: {OUTDIR.resolve()}")


if __name__ == "__main__":
    main()
